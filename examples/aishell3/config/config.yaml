# lightning.pytorch==2.0.7
seed_everything: true
trainer:
  accelerator: auto
  strategy: ddp_find_unused_parameters_true
  devices: auto
  num_nodes: 1
  precision: 32-true
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: .
      log_graph: false
      default_hp_metric: true
      prefix: ''
  callbacks:
    class_path: lightning.pytorch.callbacks.ModelCheckpoint
    init_args:
      verbose: false
      save_top_k: -1
      save_weights_only: false
      mode: min
      auto_insert_metric_name: true
      every_n_epochs: 1
  gradient_clip_val: 0.2
  fast_dev_run: false
  max_steps: -1
  max_epochs: 200
  overfit_batches: 0.0
  check_val_every_n_epoch: 1
  accumulate_grad_batches: 1
  inference_mode: true
  use_distributed_sampler: true
  detect_anomaly: false
  barebones: false
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  num_sanity_val_steps: 0
model:
  model_conf:
    dim_in: 80
    num_phoneme_tokens: 511
    dim: 1024
    heads: 8
    depth: 8
    ff_mult: 4
    attention_dropout: 0.
    activation_dropout: 0.1
    conv_pos_embed_kernel_size: 31
    conv_pos_embed_groups: 16
    conv_pos_embed_depth: 2
    p_drop_prob: 0.3
    dim_head: 128
  opt_conf:
    lr: 0.0001
    lr_init: 1.0e-06
    lr_end: 1.0e-05
    warmup_steps: 5000
    decay_steps: 40000
data:
  trainset:
    root: ./data
    meta: train.txt
    phonesets: phonesets.txt
    melspec_dir: melspec
    text_path: phone_transcripts.pt
    max_eval_sample: -1
  valset:
    root: ./data
    meta: eval.txt
    phonesets: phonesets.txt
    melspec_dir: melspec
    text_path: phone_transcripts.pt
    max_eval_sample: 8
  mel_mean: -6.546575
  mel_std: 2.4786096
  batch_size: 16
